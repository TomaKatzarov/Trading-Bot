# Asset ID Embedding Strategy for Neural Network Training

**Document Version:** 1.0  
**Created:** 2025-05-23  
**Task:** Phase 0, Task 0.5 - Asset ID Embedding Strategy Definition  
**Context:** Implementation Plan: System Refactoring and Next Development Phase (NN Data Preparation Focus)

## Overview

This document defines the strategy for representing Asset IDs in the Neural Network training pipeline, enabling a single model to learn asset-specific behaviors when trained on multiple symbols from `config/symbols.json`.

## Strategy: Simple Integer Mapping for nn.Embedding

### Chosen Approach
**Simple Integer Mapping** - Each unique symbol will be assigned a sequential integer ID (0, 1, 2, ..., N-1) for use with PyTorch `nn.Embedding` layers.

### Rationale
1. **Simplicity:** Straightforward to implement and maintain
2. **PyTorch Compatibility:** Direct compatibility with `nn.Embedding(num_embeddings, embedding_dim)` layers
3. **Scalability:** Efficiently handles the ~154 symbols in `config/symbols.json`
4. **Memory Efficiency:** Integer IDs require minimal storage compared to one-hot encoding
5. **Flexibility:** Embedding dimensions can be tuned as hyperparameters during model training

## Implementation Details

### 1. Symbol Collection and ID Assignment

**Source:** All unique symbols from `config/symbols.json` across all categories:
- `sectors`: Technology, Finance, Healthcare, Energy, Consumer, Industrials, Materials, Utilities, RealEstate
- `etfs`: Market, Sector, International, Volatility, Commodities  
- `crypto`: Major, DeFi
- Note: `indices` category symbols overlap with sector symbols and will be deduplicated

**ID Assignment Method:**
```python
# Pseudocode for ID assignment
unique_symbols = set()
for category in config['sectors', 'etfs', 'crypto']:
    for subcategory, symbols in category.items():
        unique_symbols.update(symbols)

# Sort for consistent ordering across runs
sorted_symbols = sorted(list(unique_symbols))
symbol_to_id = {symbol: idx for idx, symbol in enumerate(sorted_symbols)}
id_to_symbol = {idx: symbol for symbol, idx in symbol_to_id.items()}
```

### 2. Mapping Storage and Retrieval

**Storage Location:** `config/asset_id_mapping.json`

**File Structure:**
```json
{
    "metadata": {
        "created_date": "2025-05-23",
        "total_symbols": 154,
        "source_config": "symbols.json",
        "version": "1.0"
    },
    "symbol_to_id": {
        "AAPL": 0,
        "AAVEUSD": 1,
        "ABBV": 2,
        ...
    },
    "id_to_symbol": {
        "0": "AAPL",
        "1": "AAVEUSD", 
        "2": "ABBV",
        ...
    }
}
```

**Generation Strategy:**
- **Dynamic Generation:** The mapping will be generated by `core/data_preparation_nn.py` during its first run
- **Consistency:** Once created, the mapping file will be reused to ensure consistent IDs across training sessions
- **Validation:** The module will verify that all symbols in the current dataset exist in the mapping
- **Regeneration:** If new symbols are added to `config/symbols.json`, the mapping can be regenerated with a version increment

### 3. Integration with Neural Network Pipeline

**Data Flow in `core/data_preparation_nn.py`:**

1. **Load/Generate Mapping:**
   ```python
   def load_or_create_asset_mapping(symbols_config_path, mapping_path):
       # Load existing mapping or create new one
       # Ensure all symbols from config are mapped
       # Return symbol_to_id dictionary
   ```

2. **Feature Generation:**
   - For each data sample, include the corresponding integer Asset ID
   - Asset ID will be provided as a separate input array alongside the main feature matrix

3. **Output Format:**
   - **X (Features):** Shape `(n_samples, lookback_window, n_features)` - main technical/sentiment features
   - **Asset_IDs:** Shape `(n_samples,)` - integer Asset IDs for each sample
   - **y (Labels):** Shape `(n_samples,)` - target labels

### 4. Neural Network Model Integration

**Embedding Layer Usage:**
```python
class TradingModel(nn.Module):
    def __init__(self, num_assets, asset_embedding_dim, feature_dim, ...):
        super().__init__()
        self.asset_embedding = nn.Embedding(num_assets, asset_embedding_dim)
        # ... other layers
    
    def forward(self, features, asset_ids):
        # features: (batch_size, seq_len, feature_dim)
        # asset_ids: (batch_size,)
        
        asset_embeds = self.asset_embedding(asset_ids)  # (batch_size, asset_embedding_dim)
        # Combine with features (e.g., concatenate, add, or use in attention)
        # ... rest of forward pass
```

**Integration Options:**
1. **Concatenation:** Concatenate asset embedding with each timestep's features
2. **Addition:** Add asset embedding to a learned projection of features
3. **Attention:** Use asset embedding in attention mechanisms
4. **Separate Processing:** Process asset embedding separately and combine at final layers

## Configuration Parameters

**Embedding Dimensions:**
- **Default:** 8-16 dimensions (to be tuned as hyperparameter)
- **Range:** 4-32 dimensions depending on model architecture and performance
- **Rationale:** Sufficient to capture asset-specific patterns without overfitting

**Mapping Management:**
- **Auto-regeneration:** Disabled by default to maintain consistency
- **Manual regeneration:** Available via flag in `core/data_preparation_nn.py`
- **Version tracking:** Increment version when mapping changes

## Validation and Testing

**Validation Checks:**
1. All symbols in training data have valid Asset IDs
2. Asset ID range is [0, num_assets-1]
3. No duplicate Asset IDs for different symbols
4. Mapping consistency across different runs
5. Embedding layer compatibility (num_embeddings matches max Asset ID + 1)

**Test Cases:**
1. Mapping generation with current `config/symbols.json`
2. Mapping persistence and loading
3. Asset ID assignment for sample data
4. Integration with dummy neural network model
5. Handling of unknown symbols (should raise clear error)

## Future Considerations

**Extensibility:**
- Strategy supports adding new symbols by regenerating mapping
- Embedding dimensions can be adjusted based on model performance
- Alternative embedding strategies (e.g., pre-trained embeddings) can be explored

**Monitoring:**
- Track embedding layer weights during training to ensure meaningful asset representations
- Analyze embedding similarities to validate learned asset relationships

## Summary

The Simple Integer Mapping strategy provides a robust, scalable, and PyTorch-compatible approach for Asset ID representation. The strategy will be implemented in `core/data_preparation_nn.py` with mapping stored in `config/asset_id_mapping.json`, enabling consistent asset identification across training sessions while maintaining flexibility for future enhancements.